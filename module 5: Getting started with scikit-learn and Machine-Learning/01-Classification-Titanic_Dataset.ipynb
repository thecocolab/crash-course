{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solved-hands",
   "metadata": {
    "papermill": {
     "duration": 0.04097,
     "end_time": "2021-04-17T23:18:57.456871",
     "exception": false,
     "start_time": "2021-04-17T23:18:57.415901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Introduction**\n",
    "\n",
    "Hello,\n",
    "\n",
    "Welcome to this hands-on exercise notebook, where we will explore a simple yet comprehensive approach to address the famous Titanic disaster through machine learning. This tutorial covers a complete pipeline, guiding you through data cleaning, feature engineering, model development, and parameter tuning. While this tutorial places emphasis on feature engineering and the classification task, it serves as an excellent introduction to the broader realm of machine learning.\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "### **1. Problem Statement**\n",
    "Before we dive into the technical aspects, let's define the problem we're addressing. The goal is to predict whether a passenger survived or not during the Titanic disaster. This is a classic binary classification problem, where the target variable is binary, representing survival (1) or not (0).\n",
    "\n",
    "### **2. Dataset**\n",
    "We'll be working with the well-known Titanic dataset. This dataset contains various features about passengers, such as age, class, and ticket fare. The dataset is split into a training set (for model training) and a test set (for model evaluation).\n",
    "\n",
    "**Download the Dataset:**\n",
    "Join the competition and download the [dataset](https://www.kaggle.com/competitions/titanic/data) from kaggle.\n",
    "Make Sure the files are in the same folder as this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-dispatch",
   "metadata": {
    "papermill": {
     "duration": 0.038209,
     "end_time": "2021-04-17T23:18:57.534147",
     "exception": false,
     "start_time": "2021-04-17T23:18:57.495938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Table of Contents**\n",
    "\n",
    "## 1. Loading Data and Initial Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we will focus on loading the dataset and performing some preliminary Exploratory Data Analysis (EDA) to gain insights into the structure and nature of the data. This step is crucial for understanding the characteristics of the dataset before proceeding with further processing.\n",
    "\n",
    "**Tasks:**\n",
    "- Load the dataset into a Pandas DataFrame.\n",
    "- Display basic statistics using `describe()` and investigate the first few rows using `head()`.\n",
    "- Visualize key features to identify patterns or trends.\n",
    "\n",
    "## 2. Data Processing\n",
    "\n",
    "### 2.1 Data Cleaning: Dealing with Null Values\n",
    "\n",
    "Addressing missing data is a critical step in preparing the dataset for modeling. In this section, we'll explore strategies to handle null values, ensuring our data is ready for the machine learning pipeline.\n",
    "\n",
    "**Tasks:**\n",
    "- Identify and analyze missing values.\n",
    "- Implement appropriate strategies such as imputation or removal.\n",
    "\n",
    "### 2.2 Feature Engineering and Encoding\n",
    "\n",
    "Feature engineering involves creating new features or modifying existing ones to enhance the model's performance. Additionally, encoding categorical variables is necessary for many machine learning algorithms. In this section, we'll delve into feature engineering and encoding techniques.\n",
    "\n",
    "**Tasks:**\n",
    "- Create relevant features that might contribute to the predictive power of the model.\n",
    "- Encode categorical variables using techniques like one-hot encoding.\n",
    "\n",
    "### 2.3 Data Processing Pipeline\n",
    "\n",
    "Streamlining the data processing steps into a pipeline ensures efficiency and reproducibility. We'll create a comprehensive data processing pipeline to facilitate seamless integration into the modeling phase.\n",
    "\n",
    "**Tasks:**\n",
    "- Develop a data processing pipeline to automate the steps performed in 2.1 and 2.2.\n",
    "\n",
    "## 3. Modeling\n",
    "\n",
    "### 3.1 Evaluating Models and Making a Choice\n",
    "\n",
    "Now that the data is prepared, we can move on to the modeling phase. In this section, we'll explore different machine learning models and evaluate their performance using appropriate metrics.\n",
    "\n",
    "**Tasks:**\n",
    "- Select a set of classification models.\n",
    "- Evaluate model performance using metrics like accuracy, precision, and recall.\n",
    "\n",
    "### 3.2 Hyperparameter Tuning and Combining Models\n",
    "\n",
    "Fine-tuning model hyperparameters can significantly improve performance. Additionally, combining multiple models can enhance predictive power. This section will focus on hyperparameter tuning and model combination strategies.\n",
    "\n",
    "**Tasks:**\n",
    "- Perform hyperparameter tuning using techniques like GridSearchCV.\n",
    "- Explore ensemble methods for model combination.\n",
    "\n",
    "## 4. Results\n",
    "\n",
    "The final step involves preparing the results. This includes generating predictions on the test set.\n",
    "\n",
    "**Tasks:**\n",
    "- Generate predictions on the test set using the chosen model.\n",
    "- For fun you can create a submission file in the required format and submit it on kaggle to get your rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "consistent-resistance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:18:57.616208Z",
     "iopub.status.busy": "2021-04-17T23:18:57.614953Z",
     "iopub.status.idle": "2021-04-17T23:18:59.181874Z",
     "shell.execute_reply": "2021-04-17T23:18:59.180907Z"
    },
    "papermill": {
     "duration": 1.609242,
     "end_time": "2021-04-17T23:18:59.182052",
     "exception": false,
     "start_time": "2021-04-17T23:18:57.572810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting up the libraries that we will need \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-customs",
   "metadata": {
    "papermill": {
     "duration": 0.03728,
     "end_time": "2021-04-17T23:18:59.258682",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.221402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Loading data and some EDA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arranged-democracy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:18:59.350911Z",
     "iopub.status.busy": "2021-04-17T23:18:59.349797Z",
     "iopub.status.idle": "2021-04-17T23:18:59.400489Z",
     "shell.execute_reply": "2021-04-17T23:18:59.399646Z"
    },
    "papermill": {
     "duration": 0.1,
     "end_time": "2021-04-17T23:18:59.400722",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.300722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-persian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:18:59.496850Z",
     "iopub.status.busy": "2021-04-17T23:18:59.496111Z",
     "iopub.status.idle": "2021-04-17T23:18:59.521899Z",
     "shell.execute_reply": "2021-04-17T23:18:59.522413Z"
    },
    "papermill": {
     "duration": 0.078593,
     "end_time": "2021-04-17T23:18:59.522588",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.443995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data exploration 1: Get the first 5 rows of the data\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "orange-asian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:18:59.615126Z",
     "iopub.status.busy": "2021-04-17T23:18:59.614370Z",
     "iopub.status.idle": "2021-04-17T23:18:59.654361Z",
     "shell.execute_reply": "2021-04-17T23:18:59.653750Z"
    },
    "papermill": {
     "duration": 0.091783,
     "end_time": "2021-04-17T23:18:59.654519",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.562736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Harris, Mr. Walter</td>\n",
       "      <td>male</td>\n",
       "      <td>1601</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name   Sex Ticket        Cabin Embarked\n",
       "count                  891   891    891          204      889\n",
       "unique                 891     2    681          147        3\n",
       "top     Harris, Mr. Walter  male   1601  C23 C25 C27        S\n",
       "freq                     1   577      7            4      644"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include = ['object']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-precipitation",
   "metadata": {
    "papermill": {
     "duration": 0.038702,
     "end_time": "2021-04-17T23:18:59.733834",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.695132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The dataset comprises various attributes, each providing valuable information about the passengers on the Titanic. Let's delve into the significance of each attribute:\n",
    "\n",
    "- **Survived**: This is the target variable. A value of 0 indicates that the passenger did not survive, while a value of 1 denotes survival.\n",
    "\n",
    "- **Pclass**: This represents the passenger class, providing insights into the socio-economic status of the individual.\n",
    "\n",
    "- **Name, Sex, Age**: These attributes are self-explanatory, providing details about the passenger's name, gender, and age, respectively.\n",
    "\n",
    "- **SibSp**: Indicates the count of siblings and spouses accompanying the passenger aboard the Titanic, shedding light on the passenger's family connections.\n",
    "\n",
    "- **Parch**: Reflects the count of children and parents accompanying the passenger aboard the Titanic, offering insights into family relationships.\n",
    "\n",
    "- **Ticket**: Represents the unique ticket ID associated with the passenger, providing a means of identifying individuals.\n",
    "\n",
    "- **Fare**: Indicates the amount paid by the passenger for the ticket, measured in pounds. This serves as an indicator of economic capacity.\n",
    "\n",
    "- **Cabin**: Specifies the passenger's cabin number, offering information about their accommodation within the ship.\n",
    "\n",
    "- **Embarked**: Signifies the location where the passenger boarded the Titanic, providing a glimpse into the embarkation point.\n",
    "\n",
    "Understanding the nuances of each attribute is crucial for effective data analysis and modeling. As we progress through the notebook, we'll leverage these attributes to build a predictive model for survival outcomes during the Titanic disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-parts",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:18:59.830994Z",
     "iopub.status.busy": "2021-04-17T23:18:59.830194Z",
     "iopub.status.idle": "2021-04-17T23:18:59.834927Z",
     "shell.execute_reply": "2021-04-17T23:18:59.834143Z"
    },
    "papermill": {
     "duration": 0.061302,
     "end_time": "2021-04-17T23:18:59.835083",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.773781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data exploration 2: Get train info\n",
    "\n",
    "train.ADD CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-miracle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:18:59.919968Z",
     "iopub.status.busy": "2021-04-17T23:18:59.919284Z",
     "iopub.status.idle": "2021-04-17T23:18:59.933209Z",
     "shell.execute_reply": "2021-04-17T23:18:59.933804Z"
    },
    "papermill": {
     "duration": 0.057645,
     "end_time": "2021-04-17T23:18:59.933979",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.876334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same for test\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-professor",
   "metadata": {
    "papermill": {
     "duration": 0.041823,
     "end_time": "2021-04-17T23:19:00.015986",
     "exception": false,
     "start_time": "2021-04-17T23:18:59.974163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The training set exhibits missing values in the Age, Cabin, and Embarked columns, necessitating careful consideration and appropriate handling during the data preprocessing phase.\n",
    "\n",
    "Similarly, the test set presents missing values in the Age, Cabin, and Fare columns, demanding thoughtful imputation or removal strategies to ensure the dataset's completeness and suitability for subsequent modeling steps.\n",
    "\n",
    "Addressing these missing values effectively is crucial to maintain the integrity and reliability of the dataset, ultimately contributing to the accuracy and robustness of the machine learning models developed in this tutorial. Note that when dealing with medical data (i.e brain data; strategies might differ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gorgeous-stylus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:00.103517Z",
     "iopub.status.busy": "2021-04-17T23:19:00.102681Z",
     "iopub.status.idle": "2021-04-17T23:19:00.111609Z",
     "shell.execute_reply": "2021-04-17T23:19:00.111057Z"
    },
    "papermill": {
     "duration": 0.05437,
     "end_time": "2021-04-17T23:19:00.111782",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.057412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data exploration 3: Get the number of missing values in the train data\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data exploration 4: Get the number of passengers that survived and those that did not\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "talented-mounting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:00.199508Z",
     "iopub.status.busy": "2021-04-17T23:19:00.198804Z",
     "iopub.status.idle": "2021-04-17T23:19:00.202677Z",
     "shell.execute_reply": "2021-04-17T23:19:00.202008Z"
    },
    "papermill": {
     "duration": 0.049985,
     "end_time": "2021-04-17T23:19:00.202833",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.152848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets make a copy of the data\n",
    "train_copy = train.copy()\n",
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-invalid",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:00.294072Z",
     "iopub.status.busy": "2021-04-17T23:19:00.292893Z",
     "iopub.status.idle": "2021-04-17T23:19:00.301684Z",
     "shell.execute_reply": "2021-04-17T23:19:00.300510Z"
    },
    "papermill": {
     "duration": 0.058219,
     "end_time": "2021-04-17T23:19:00.301995",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.243776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlations(data):\n",
    "    \"\"\"\n",
    "    Plot the correlations of features with the 'Survived' target variable.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame, the input dataset\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    correlation_matrix = data.corr()\n",
    "    correlation_with_survival = correlation_matrix[\"Survived\"].sort_values(ascending=False)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=correlation_with_survival.values, y=correlation_with_survival.index, palette=\"viridis\")\n",
    "\n",
    "    # Adding annotations\n",
    "    for i, value in enumerate(correlation_with_survival):\n",
    "        plt.text(value + 0.01 if value >= 0 else value - 0.05, i, f\"{value:.3f}\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "    # Setting plot properties\n",
    "    plt.title(\"Correlation with 'Survived'\", fontsize=16)\n",
    "    plt.xlabel(\"Correlation Coefficient\", fontsize=12)\n",
    "    plt.ylabel(\"Features\", fontsize=12)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above function on train\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-diary",
   "metadata": {
    "papermill": {
     "duration": 0.040992,
     "end_time": "2021-04-17T23:19:00.385834",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.344842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Parch and SibSp attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-rapid",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:00.477485Z",
     "iopub.status.busy": "2021-04-17T23:19:00.476698Z",
     "iopub.status.idle": "2021-04-17T23:19:00.479685Z",
     "shell.execute_reply": "2021-04-17T23:19:00.480322Z"
    },
    "papermill": {
     "duration": 0.053073,
     "end_time": "2021-04-17T23:19:00.480503",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.427430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What percentage of passengers have Parch values equal to 0, and what percentage have SibSp values equal to 0 in the training dataset?\n",
    "ADD CODE HERE\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-faith",
   "metadata": {
    "papermill": {
     "duration": 0.042173,
     "end_time": "2021-04-17T23:19:00.565746",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.523573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The prevalence of Parch and SibSp values at 0 suggests a predominant absence of parents/children and siblings/spouses among passengers. Independently, these attributes exhibit limited correlation with the target variable, signifying a potential challenge in extracting meaningful insights.\n",
    "\n",
    "However, recognizing the importance of familial context, combining these attributes offers an opportunity to derive a more informative feature. Introducing a novel attribute named \"Family Size\" allows us to categorize passengers into three meaningful groups: Small, Medium, and Large. Additionally, an \"Alone\" category is introduced for passengers without any family members aboard the ship.\n",
    "\n",
    "This consolidation not only simplifies the dataset but also captures the essence of familial relationships, potentially enhancing the model's ability to discern patterns related to survival outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-helen",
   "metadata": {
    "papermill": {
     "duration": 0.042258,
     "end_time": "2021-04-17T23:19:00.650778",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.608520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Cabin Attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dominant-sleeve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:00.739831Z",
     "iopub.status.busy": "2021-04-17T23:19:00.739153Z",
     "iopub.status.idle": "2021-04-17T23:19:00.748906Z",
     "shell.execute_reply": "2021-04-17T23:19:00.748195Z"
    },
    "papermill": {
     "duration": 0.054977,
     "end_time": "2021-04-17T23:19:00.749053",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.694076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#What percentage of missing values does the 'Cabin' attribute have in the training and test datasets?\n",
    "ADD CODE HERE \n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-comparison",
   "metadata": {
    "papermill": {
     "duration": 0.042645,
     "end_time": "2021-04-17T23:19:00.835160",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.792515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "While it holds true that a significant portion of the 'Cabin' attribute contains missing values, outright dropping this feature is not advisable. This is because certain cabins exhibit distinct survival rates, suggesting that cabin location could be a contributing factor. For instance, cabins situated closer to the surface might have higher survival rates.\n",
    "\n",
    "After conducting further research, it has come to light that the first letter of the 'Cabin' values corresponds to the decks where the cabins are situated. Leveraging this insight, we plan to transform the 'Cabin' attribute into a new 'Deck' attribute. This transformation allows us to explore the relationship between cabin location (deck) and survival rates more comprehensively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-exposure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:00.931881Z",
     "iopub.status.busy": "2021-04-17T23:19:00.931175Z",
     "iopub.status.idle": "2021-04-17T23:19:00.935062Z",
     "shell.execute_reply": "2021-04-17T23:19:00.934401Z"
    },
    "papermill": {
     "duration": 0.057619,
     "end_time": "2021-04-17T23:19:00.935207",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.877588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new attribute named 'Deck' for both the training and test datasets by extracting the first letter from the 'Cabin' values. If the 'Cabin' value is null, assign 'X' to the 'Deck' attribute.\n",
    "ADD CODE HERE\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "centered-waters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:01.033723Z",
     "iopub.status.busy": "2021-04-17T23:19:01.032727Z",
     "iopub.status.idle": "2021-04-17T23:19:01.038539Z",
     "shell.execute_reply": "2021-04-17T23:19:01.039118Z"
    },
    "papermill": {
     "duration": 0.060821,
     "end_time": "2021-04-17T23:19:01.039304",
     "exception": false,
     "start_time": "2021-04-17T23:19:00.978483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What is the count of passengers for each combination of 'Deck' and 'Pclass' in the 'train_copy' dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patient-adams",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:01.131102Z",
     "iopub.status.busy": "2021-04-17T23:19:01.130131Z",
     "iopub.status.idle": "2021-04-17T23:19:01.139847Z",
     "shell.execute_reply": "2021-04-17T23:19:01.140405Z"
    },
    "papermill": {
     "duration": 0.058032,
     "end_time": "2021-04-17T23:19:01.140576",
     "exception": false,
     "start_time": "2021-04-17T23:19:01.082544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What is the count of passengers for each combination of 'Deck' and 'Pclass' in the 'test_copy' dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-capacity",
   "metadata": {
    "papermill": {
     "duration": 0.04292,
     "end_time": "2021-04-17T23:19:01.227388",
     "exception": false,
     "start_time": "2021-04-17T23:19:01.184468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you've seen the movie, you're aware that the decks on the Titanic were segregated, with certain decks designated exclusively for a specific passenger class. Here's a breakdown:\n",
    "- Decks A, B, and C were reserved solely for 1st class passengers.\n",
    "- Decks D and E were accessible to passengers across all classes.\n",
    "- Decks F and G were shared between 2nd and 3rd class passengers.\n",
    "  \n",
    "Passengers labeled as 'X' represent missing values in the 'Cabin' feature, making it challenging to determine the real deck allocation for these individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-communist",
   "metadata": {
    "papermill": {
     "duration": 0.042527,
     "end_time": "2021-04-17T23:19:01.313148",
     "exception": false,
     "start_time": "2021-04-17T23:19:01.270621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-civilian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:01.424712Z",
     "iopub.status.busy": "2021-04-17T23:19:01.423986Z",
     "iopub.status.idle": "2021-04-17T23:19:01.868844Z",
     "shell.execute_reply": "2021-04-17T23:19:01.869332Z"
    },
    "papermill": {
     "duration": 0.512751,
     "end_time": "2021-04-17T23:19:01.869514",
     "exception": false,
     "start_time": "2021-04-17T23:19:01.356763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a FacetGrid using the 'train' dataset, with separate columns for passengers who survived and those who did not. \n",
    "#Map a histogram for the 'Age' attribute in each column to visualize the distribution of ages among survivors and non-survivors.\n",
    "g = sns.FacetGrid(ADD CODE HERE, ADD CODE HERE)\n",
    "g = g.map(sns.histplot, ADD CODE HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-holmes",
   "metadata": {
    "papermill": {
     "duration": 0.043386,
     "end_time": "2021-04-17T23:19:01.956798",
     "exception": false,
     "start_time": "2021-04-17T23:19:01.913412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The distribution of ages appears to follow a Gaussian distribution. Notably, there are discernible differences in the age distribution between the subpopulations of survivors and non-survivors. Specifically, individuals aged between 60 and 80 seem to have lower survival probabilities, while children and young passengers exhibit higher chances of survival.\n",
    "\n",
    "Considering these patterns, it is prudent to transform the 'Age' feature into categorical groups. This categorical approach aligns with the observed variations in survival probabilities among different age categories, providing a more nuanced representation of the relationship between age and survival outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-canadian",
   "metadata": {
    "papermill": {
     "duration": 0.044464,
     "end_time": "2021-04-17T23:19:02.045051",
     "exception": false,
     "start_time": "2021-04-17T23:19:02.000587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fare and Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-wedding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:02.138916Z",
     "iopub.status.busy": "2021-04-17T23:19:02.137885Z",
     "iopub.status.idle": "2021-04-17T23:19:02.147409Z",
     "shell.execute_reply": "2021-04-17T23:19:02.146830Z"
    },
    "papermill": {
     "duration": 0.058195,
     "end_time": "2021-04-17T23:19:02.147557",
     "exception": false,
     "start_time": "2021-04-17T23:19:02.089362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the number of missing values in the 'Fare' attribute of the train/test dataset.\n",
    "# Determine the count of missing values in the 'Embarked' attribute of the train/test dataset.\n",
    "\n",
    "f_train = ADD CODE HERE\n",
    "e_train = ADD CODE HERE\n",
    "\n",
    "f_test = ADD CODE HERE\n",
    "e_test = ADD CODE HERE\n",
    "\n",
    "# Display the results.\n",
    "print(f'{f_train} value(s) of Fare attribute and {e_train} value(s) of Embarked attribute are missing in train')\n",
    "print(f'{f_test} value(s) of Fare attribute and {e_test} value(s) of Embarked attribute are missing in test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-processing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:02.241658Z",
     "iopub.status.busy": "2021-04-17T23:19:02.241027Z",
     "iopub.status.idle": "2021-04-17T23:19:02.256186Z",
     "shell.execute_reply": "2021-04-17T23:19:02.256740Z"
    },
    "papermill": {
     "duration": 0.063433,
     "end_time": "2021-04-17T23:19:02.256923",
     "exception": false,
     "start_time": "2021-04-17T23:19:02.193490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[test['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-adolescent",
   "metadata": {
    "papermill": {
     "duration": 0.045427,
     "end_time": "2021-04-17T23:19:02.347710",
     "exception": false,
     "start_time": "2021-04-17T23:19:02.302283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* The passengers that has a missing value for fare is from class 3 and has 0 family members with him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handled-pipeline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:02.448590Z",
     "iopub.status.busy": "2021-04-17T23:19:02.447851Z",
     "iopub.status.idle": "2021-04-17T23:19:03.021572Z",
     "shell.execute_reply": "2021-04-17T23:19:03.020901Z"
    },
    "papermill": {
     "duration": 0.624756,
     "end_time": "2021-04-17T23:19:03.021725",
     "exception": false,
     "start_time": "2021-04-17T23:19:02.396969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVhklEQVR4nO3df5BdZX3H8ffH/OJHCEnIJt2G/CA2g+BEY0gRK1AUSgPjGJwCBVGixUmt0cERa4PagjPWYmutaAFFYAiMYgBlSBkUMMBoHcEECCwhAjFkl6SBJARIwi83N9/+cZ9dbpab7Gb3/njuvZ/XzJ17znPOPee72fvks+fZs89VRGBmZpabt9W7ADMzs3IcUGZmliUHlJmZZckBZWZmWXJAmZlZlhxQZmaWJQdUnUj6iqTVkh6TtErSeyt03A9LWlyhY+2swDFGSVoqaa2kByVNr0Bp1uRaqH+cKOlhSbsknVmJuprJ8HoX0IokvQ/4EDAnIt6QNAEYuR+vHx4Ru8pti4hlwLLKVFoRFwAvRsSfSToH+Cbwt3WuyTLWYv2jC/gE8MU615ElX0HVRzuwNSLeAIiIrRHxfwCS1qcOiaS5ku5Py5dKulHSb4AbJT0g6Z09B5R0f9r/E5L+W9KhkjolvS1tP1jSs5JGSHq7pF9IekjSryW9I+1zhKTfSuqQ9PUKfa3zgSVp+VbgZEmq0LGtObVM/4iI9RHxGLC7EsdrNg6o+rgbmCLpKUlXSvrLAb7uaOCUiDgXWAqcDSCpHWiPiJU9O0bEy8AqoOfYHwLuiohu4GrgcxFxDMWf3K5M+1wOXBURs4BNeysiddpVZR6nlNl9MvBsqmkX8DJw2AC/XmtNrdQ/bB88xFcHEbFT0jHACcAHgKWSFkfE9f28dFlEvJaWb6bYkS+h2BFvLbP/UorDafcB5wBXShoN/AVwS8mFzKj0/H7gb9LyjRSH48rVf0I/dZoNmvuH9XBA1UlEFID7gfsldQALgOuBXbx5ZXtAn5e9UvL6jZJekPQuip3s02VOswz4hqTxwDHAvcDBwEsRMXtvpfVXu6RfA4eU2fTFiPhln7aNwBRgg6ThwKHAC/2dw1pbC/UP2wcP8dWBpCMlzSxpmg10puX1FDsLvPnT2t4sBb4EHJrGsfcQETuBFRSHJu6IiEJEbAeekXRWqkWS3p1e8huKP0kCnLe3k0bECRExu8yjXOdbRvE/F4AzgXvDMxTbPrRY/7B9cEDVx2hgiaQnJD1Gcez80rTta8DlklYChX6OcyvFDnPzPvZZCnwsPfc4D7hA0qPAaoo3MgBcCCxKP7FOHviXs0/XAodJWgt8AajILb7W1Fqmf0j6c0kbgLOAH0haXYnjNgv5h1kzM8uRr6DMzCxLDigzM8uSA8rMzLLkgDIzsyxlEVDz5s0Lin9f4IcfzfoYNPcPP1rgUVYWAbV169Z6l2CWLfcPa1VZBJSZmVlfDigzM8uSA8rMzLLkgDIzsyw5oMzMLEsNE1CFQoF169ZRKPQ3P6SZmTWDhgmozs5OPvr16+ns7Ox/ZzMza3gNE1AABxw6od4lmJlZjTRUQJmZWetwQJmZWZYcUGZmliUHlJmZZckBZWZmWXJAmZlZlhxQZmaWJQeUmZllyQFlZmZZckCZmVmWHFBmZpYlB5SZmWXJAWVmZllyQJmZWZb6DShJUyTdJ+kJSaslXZjax0u6R9LT6Xlcapek70paK+kxSXOq/UWYmVnzGcgV1C7goog4GjgOWCTpaGAxsDwiZgLL0zrAacDM9FgIXFXxqs3MrOn1G1ARsSkiHk7LO4A1wGRgPrAk7bYEOCMtzwduiKIHgLGS2itduJmZNbf9+h2UpOnAe4AHgUkRsSlteg6YlJYnA8+WvGxDajMzMxuwAQeUpNHAT4HPR8T20m0REUDsz4klLZS0UtLKLVu27M9LzZqe+4fZAANK0giK4fSjiPhZan6+Z+guPW9O7RuBKSUvPzy17SEiro6IuRExt62tbbD1mzUl9w+zgd3FJ+BaYE1EfLtk0zJgQVpeANxe0n5+upvvOODlkqFAMzOzARk+gH3eD3wc6JC0KrV9GbgMuFnSBUAncHbadidwOrAWeBX4ZCULNjOz1tBvQEXE/wLay+aTy+wfwKIh1mVmZi3OM0mYmVmWHFBmZpYlB5SZmWXJAWVmZllyQJmZWZYcUGZmliUHlJmZZckBZWZmWXJAmZlZlhxQZmaWJQeUmZllyQFlZmZZckCZmVmWHFBmZpYlB5SZmWXJAWVmZllyQJmZWZYcUGZmliUHlJmZZckBZWZmWXJAmZlZlhxQZmaWpX4DStJ1kjZLeryk7VJJGyWtSo/TS7ZdLGmtpCcl/XW1Cjczs+Y2kCuo64F5Zdr/KyJmp8edAJKOBs4B3plec6WkYZUq1szMWke/ARURvwK2DfB484GfRMQbEfEMsBY4dgj1mZlZixrK76A+K+mxNAQ4LrVNBp4t2WdDansLSQslrZS0csuWLUMow6z5uH+YDT6grgLeDswGNgH/ub8HiIirI2JuRMxta2sbZBlmzcn9w2yQARURz0dEISJ2Az/kzWG8jcCUkl0PT21mZmb7ZVABJam9ZPUjQM8dfsuAcySNknQEMBP43dBKNDOzVjS8vx0k3QScBEyQtAG4BDhJ0mwggPXA3wNExGpJNwNPALuARRFRqErlZmbW1PoNqIg4t0zztfvY/1+Bfx1KUWZmZp5JwszMsuSAMjOzLDmgzMwsSw4oMzPLkgPKzMyy5IAyM7MsOaDMzCxLDigzM8uSA8rMzLLkgDIzsyw5oMzMLEsOKDMzy5IDyszMsuSAMjOzLDmgzMwsSw4oMzPLkgPKzMyy5IAyM7MsOaDMzCxLDigzM8uSA8rMzLLkgDIzsyz1G1CSrpO0WdLjJW3jJd0j6en0PC61S9J3Ja2V9JikOdUs3szMmtdArqCuB+b1aVsMLI+ImcDytA5wGjAzPRYCV1WmTDMzazX9BlRE/ArY1qd5PrAkLS8BzihpvyGKHgDGSmqvUK1mZtZCBvs7qEkRsSktPwdMSsuTgWdL9tuQ2t5C0kJJKyWt3LJlyyDLMGtO7h9mFbhJIiICiEG87uqImBsRc9va2oZahllTcf8wG3xAPd8zdJeeN6f2jcCUkv0OT21mZmb7ZbABtQxYkJYXALeXtJ+f7uY7Dni5ZCjQzMxswIb3t4Okm4CTgAmSNgCXAJcBN0u6AOgEzk673wmcDqwFXgU+WYWazcysBfQbUBFx7l42nVxm3wAWDbUoMxuY7u5uOjo69mibNWsWI0aMqFNFZpXTb0CZWb46Ojr4zBXLGNM+HYDtm9Zz5SKYM8d/I2+NzwFl1uDGtE9n/NQj612GWcV5Lj4zM8uSA8rMzLLkgDIzsyw5oMzMLEsOKDMzy5IDyszMsuSAMjOzLDXU30HF7t10dXUBMG3aNIYNG1bniszMrFoaKqBe37GNr976CCNHreaaRacxY8aMepdklpXdhV2sWbNmjzZPfWSNqqECCuDAcRMZdcCoepdhlqWdmzfwrTtfp21NN+Cpj6yxNVxAmdm+jZ441VMfWVPwTRJmZpYlB5SZmWXJQ3xmTcw3TVgjc0CZNTHfNGGNzAFl1uR804Q1Kv8OyszMsuSAMjOzLDmgzMwsS0P6HZSk9cAOoADsioi5ksYDS4HpwHrg7Ih4cWhlmplZq6nEFdQHImJ2RMxN64uB5RExE1ie1s3MzPZLNYb45gNL0vIS4IwqnMPMzJrcUAMqgLslPSRpYWqbFBGb0vJzwKRyL5S0UNJKSSu3bNkyxDLMmov7h9nQA+r4iJgDnAYsknRi6caICIoh9hYRcXVEzI2IuW1tbUMsw6y5uH+YDTGgImJjet4M3AYcCzwvqR0gPW8eapFmZtZ6Bh1Qkg6WdEjPMnAq8DiwDFiQdlsA3D7UIs3MrPUM5TbzScBtknqO8+OI+IWkFcDNki4AOoGzh17mnmJ3ga6uLn/su5lZExt0QEXEOuDdZdpfAE4eSlH9ee2lrVx0zSpumTrVH/tuZtakGnYmiVFjDqt3CWZmVkUNG1BmZtbcGj6gCoUC69ato1Ao1LsUMzOroIYPqM7OTj769evp7OysdylmZlZBTfGBhaMOGU9XVxeA7+wzM2sSDX8FBfD6jm189dZH+NQVP/eVlJlZk2iKKyiAA8dNZNQBo+pdhpmZVUjTBJSZ7b/u7m46Ojr2aJs1axYjRoyoU0Vmb3JAmbWwjo4OPnPFMsa0Twdg+6b1XLkI5syZ07uPQ8zqxQFl1uLGtE9n/NQj97p9ICFmVg0NG1Cxe3fvnXvlP9DDzCqlvxAzq4aGDag3dr7IV299hMJr2+nu7gY8iayZWTNp6NvMDxw3kQPHTuhdL04ie5dvNTczawINHVDleBJZM7Pm0HQBZWZmzaEhAqpQKP5uyTdDmJm1joYIqM7OTj5/xU97b4YwM7Pm1xABBTDqkHH1LsHMzGqoYW8z70+hUKCzs9O3nJuV2F3YxZo1a3rX16xZA7F/Y+d9jwGeWcKqo2kDqudzom68+OO9AVUaVj0B1rfdrJnt3LyBb935Om1risPlmzp+y9gZ7+7dXi58+oZY32N4ZgmrlqYNKCh+TtSKFSv44coXkeCaRacxY8YMoBhgn7ri58Tu3VwyfxYnnHCCQ8pawuiJU3tnhdi+af0e2/qGD7w1xPoeo6++c/d1d3cjieHD3/zvxldcNhBNF1ClUyC9vn0b31j6JO3vOp6RI4e/ZZaJg8ZP4tVtz3PRNXdxy9SpTJs2zcOC1vL6hk/fEOur3LDh95Y/xZg/PQIoBtzw0eNoO+IdvccrveLyZLS2N1ULKEnzgMuBYcA1EXFZtc5Vqu8USCMPGQv0zDKxilumTu29iuoxcvQ4urq66Orq4p+W3MtN//yJt+xjZuXtbdiw9CptxJiJe73iqsRktP2FnEOwNir971yVgJI0DLgC+CtgA7BC0rKIeKIa5+vrwHETKYwayRvPb9ijvSeIev6uqmdYvTTU3jZqNM888wyFQoFhw4aV/b1VoVAAYMaMGW+50trbzRmFQoF169bt9XX7q/Q8wD6PXe73bb6JxCppX8OGfZW74hrzJ9N6Xz+YmzD6C7m+21/a+AcuPGUNRx11FPDWYUgPSw5OpWe+r9YV1LHA2ohYByDpJ8B8YNAB9caOF9n1x1289uJmCq9t5487XhrQMtC7vmPrc1x0zYsU3tjJK9u2MumoY3v3O2jsRAB2bHqGT3/jEca0T2fEyBFcdv4HmTp1KgBdXV0svuFeXt/xIt1v/JErvnBu77YeXV1dXPi9W7j8c2ftsa2rq4tPX3YNw0YeXPZ1+6v0PMA+j91TN9D79fS8/rb/uMhXiw2uNBBe2bqJ4a+/zraDD6rIejWO+fwTK7h05U7Gtj8OwAvrVnPotKNBKrv91Ree48sfPaU3TMrpG2h92/puf23bZi69ft0eNQw78BDGtk8tuz6QGqz892EoFPt5i+mADiqdCcyLiE+l9Y8D742Iz5bssxBYmFaPBJ7s57ATgK0VL3bg6n1+19DYNWyNiHkD3Xk/+0cj/ns0Yw31Pn8j11C2f9TtJomIuBq4eqD7S1oZEXOrWFLW53cNrVXD/vSPVvj3aIQa6n3+ZqyhWjNJbASmlKwfntrMzMwGpFoBtQKYKekISSOBc4BlVTqXmZk1oaoM8UXELkmfBe6ieJv5dRGxeoiHHfBwYJXU+/zgGnq4hj3lUItrqP/5oclqqMpNEmZmZkPVMLOZm5lZa3FAmZlZlrIPKEnzJD0paa2kxVU8z3WSNkt6vKRtvKR7JD2dnseldkn6bqrpMUkVmcZZ0hRJ90l6QtJqSRfWsg5JB0j6naRH0/m/ltqPkPRgOs/SdOMLkkal9bVp+/Qh/hOU1jJM0iOS7qhHDZLWS+qQtErSytRW0/fDAGp036hhHbn0j3r3jXTs2vSPiMj2QfEGiz8AM4CRwKPA0VU614nAHODxkrZ/Bxan5cXAN9Py6cDPAQHHAQ9WqIZ2YE5aPgR4Cji6VnWk44xOyyOAB9NxbwbOSe3fB/4hLX8G+H5aPgdYWsHvxxeAHwN3pPWa1gCsByb0aavp+6Gf+tw3atg30jGz6B/17hvpeDXpH1XtRBX4R3gfcFfJ+sXAxVU83/Q+nfBJoD0ttwNPpuUfAOeW26/C9dxOcT7DmtcBHAQ8DLyX4l+FD+/7PaF4l+b70vLwtJ8qcO7DgeXAB4E70hu71jWU64B1fT/0qcV9o059Ix2vLv0jh76RjleT/pH7EN9k4NmS9Q2prVYmRcSmtPwcMKlWdaXL8fdQ/CmtZnWk4YNVwGbgHoo/pb8UEbvKnKP3/Gn7y8BhQzl/8h3gS8DutH5YHWoI4G5JD6k47RDU8f1QhvtGjftGOne9+8d3qH/fgBr1j6b7PKhqiYiQVJN78iWNBn4KfD4ititNolmLOiKiAMyWNBa4DXhHtc5VjqQPAZsj4iFJJ9Xy3H0cHxEbJU0E7pH0+9KNtXw/5K5V+kY6R936R0Z9A2rUP3K/gqr3lEnPS2oHSM+bq12XpBEUO+CPIuJn9aojIl4C7qM4ZDBWUs8PM6Xn6D1/2n4o8MIQT/1+4MOS1gM/oTiUcXmNayAiNqbnzRT/IzqWOnwf9sF9o051QN36RxZ9A2rXP3IPqHpPmbQMWJCWF1Ac9+5pPz/dnXIc8HLJpe2gqfjj4LXAmoj4dq3rkNSWfjJE0oEUx/jXUOyIZ+7l/D11nQncG2mQebAi4uKIODwiplP8ft8bEefVsgZJB0s6pGcZOBV4nBq/H/rhvlHjOurdP3LoG1Dj/lGJX5hV80HxDpCnKI71fqWK57kJ2AR0UxwjvYDieO1y4Gngl8D4tK8ofiDjH4AOYG6Fajie4tjuY8Cq9Di9VnUA7wIeSed/HPiX1D4D+B2wFrgFGJXaD0jra9P2GRX+npzEm3cq1ayGdK5H02N1z/uu1u8H9418+kZu/aNefaPW/cNTHZmZWZZyH+IzM7MW5YAyM7MsOaDMzCxLDigzM8uSA8rMzLLkmSSajKQCxVs5e5wREevrVI5ZVtw/GotvM28yknZGxOj9fI0ovhd297uzWQNz/2gsHuJrcpJGS1ou6WEVP79lfmqfruJnCd1A8Y8Op0j6R0kr0me2fK2+lZtVn/tH3jzE13wOVHG2ZYBngLOAj0RxYs0JwAOSeqbEmQksiIgHJJ2a1o+l+JffyySdGBG/qnH9ZtXk/tFAHFDN57WImN2zkibY/IakEylO0T+ZN6fB74yIB9LyqenxSFofTbFDugNaM3H/aCAOqOZ3HtAGHBMR3Wkm5APStldK9hPwbxHxgxrXZ1ZP7h8Z8++gmt+hFD9DplvSB4Bpe9nvLuDvVPy8HSRNVvGzXsyamftHxnwF1fx+BPyPpA5gJfD7cjtFxN2SjgJ+W7xpiZ3Ax3jzM13MmpH7R8Z8m7mZmWXJQ3xmZpYlB5SZmWXJAWVmZllyQJmZWZYcUGZmliUHlJmZZckBZWZmWfp/0c3Xwi4K+9IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g = g.map(sns.histplot, \"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-fault",
   "metadata": {
    "papermill": {
     "duration": 0.046477,
     "end_time": "2021-04-17T23:19:03.116170",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.069693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Fare distribution is very skewed and might result in badbehaviour in our model. Transforming it into log seems like a good solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-personal",
   "metadata": {
    "papermill": {
     "duration": 0.046247,
     "end_time": "2021-04-17T23:19:03.209074",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.162827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-stewart",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:03.307074Z",
     "iopub.status.busy": "2021-04-17T23:19:03.306387Z",
     "iopub.status.idle": "2021-04-17T23:19:03.309460Z",
     "shell.execute_reply": "2021-04-17T23:19:03.309970Z"
    },
    "papermill": {
     "duration": 0.055281,
     "end_time": "2021-04-17T23:19:03.310146",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.254865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many unique values does the 'Ticket' attribute have in the given dataset?\n",
    "ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-terrain",
   "metadata": {
    "papermill": {
     "duration": 0.04814,
     "end_time": "2021-04-17T23:19:03.405880",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.357740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Given the extensive number of unique tickets for analysis, a more manageable approach is to introduce a new attribute, 'ticket_freq,' in lieu of individual tickets. This attribute captures the frequency of each ticket, reducing the complexity of the dataset.\n",
    "\n",
    "It's worth noting that numerous passengers traveled in groups comprising friends, nannies, maids, and others. While not officially recognized as family units, these individuals shared the same ticket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-administration",
   "metadata": {
    "papermill": {
     "duration": 0.046537,
     "end_time": "2021-04-17T23:19:03.499896",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.453359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-coating",
   "metadata": {
    "papermill": {
     "duration": 0.047403,
     "end_time": "2021-04-17T23:19:03.594417",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.547014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the 'Name' attribute, a more insightful analysis can be conducted by extracting the title. While extracting family names is a potential avenue, it involves considerable time and complexity. Therefore, I will focus specifically on extracting and analyzing titles for a more efficient and informative approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "median-columbia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:03.692641Z",
     "iopub.status.busy": "2021-04-17T23:19:03.691886Z",
     "iopub.status.idle": "2021-04-17T23:19:03.703918Z",
     "shell.execute_reply": "2021-04-17T23:19:03.704416Z"
    },
    "papermill": {
     "duration": 0.063419,
     "end_time": "2021-04-17T23:19:03.704610",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.641191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_copy['Title'] = train_copy['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controlled-holiday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:03.802854Z",
     "iopub.status.busy": "2021-04-17T23:19:03.802179Z",
     "iopub.status.idle": "2021-04-17T23:19:03.809984Z",
     "shell.execute_reply": "2021-04-17T23:19:03.810505Z"
    },
    "papermill": {
     "duration": 0.059563,
     "end_time": "2021-04-17T23:19:03.810762",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.751199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Provide the distribution of titles within the 'Title' attribute in the 'train_copy' dataset\n",
    "ADD CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-harvey",
   "metadata": {
    "papermill": {
     "duration": 0.046892,
     "end_time": "2021-04-17T23:19:03.905680",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.858788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Observing the data, it becomes evident that there are four major categories, and all other titles can be grouped into one of these four. In the upcoming feature engineering section, we will streamline this attribute by creating four distinct categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-sword",
   "metadata": {
    "papermill": {
     "duration": 0.047016,
     "end_time": "2021-04-17T23:19:03.999843",
     "exception": false,
     "start_time": "2021-04-17T23:19:03.952827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Data Processing**\n",
    "### 2.1 Data Cleaning: Addressing Missing Values\n",
    "\n",
    "Upon scrutiny in the preceding section, we observed that certain attributes exhibit a limited number of missing values, while others surpass the 70% mark. Here, we employ distinct strategies to handle the missing data for each attribute.\n",
    "\n",
    "* Filling Missing Age Values:\n",
    "   - Replacing missing numerical values using the median is a common approach. However, given the varying age ranges across passenger classes, we adopt a nuanced approach. Missing values in age will be imputed with the median age corresponding to each class, separately for male and female passengers.\n",
    "\n",
    "* Handling Missing Fare Values:\n",
    "   - With only one missing value in the 'Fare' attribute, we opt to fill it with the median fare for 3rd class passengers traveling alone.\n",
    "\n",
    "* Managing Missing Embarked Values:\n",
    "   - For the 'Embarked' attribute, the most frequent port, which is 'S,' will be used to fill the missing values.\n",
    "\n",
    "* Cabin Attribute Treatment:\n",
    "   - Dealing with the 'Cabin' attribute is deferred to the feature engineering section, where a new attribute will be created.\n",
    "\n",
    "These tailored approaches ensure a targeted and effective resolution of missing values in preparation for subsequent stages of analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3ff13",
   "metadata": {},
   "source": [
    "## MiniTutorial: What are classes and what are they used for?\n",
    "In programming, a class is a blueprint or a template for creating objects. Objects are instances of a class, and classes define the properties (attributes) and behaviors (methods) that these objects will have. \n",
    "\n",
    "Here's a brief overview:\n",
    "\n",
    "- **Class:** A class is a user-defined data type that encapsulates data and the functions that operate on that data. It serves as a way to bundle data and functionality together.\n",
    "\n",
    "- **Object:** An object is an instance of a class. It represents a real-world entity and has attributes (characteristics) and methods (functions) associated with it.\n",
    "\n",
    "- **Attributes:** Attributes are variables that store data. They represent the characteristics or properties of an object.\n",
    "\n",
    "- **Methods:** Methods are functions that operate on the data stored in the object. They define the behavior of the object.\n",
    "\n",
    "- **Instance:** Creating an instance of a class means creating an object based on that class. Each instance has its own set of attributes, but it shares the methods defined by the class.\n",
    "\n",
    "In Python, classes are a fundamental concept in object-oriented programming (OOP) and are widely used for creating reusable and modular code. They enable the organization of code into logical structures, making it easier to manage and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aging-election",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:04.106991Z",
     "iopub.status.busy": "2021-04-17T23:19:04.106140Z",
     "iopub.status.idle": "2021-04-17T23:19:04.109208Z",
     "shell.execute_reply": "2021-04-17T23:19:04.108588Z"
    },
    "papermill": {
     "duration": 0.059663,
     "end_time": "2021-04-17T23:19:04.109466",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.049803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate the median fare for a man in the third class with no family\n",
    "        self.med_fare_ = X.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "        \n",
    "        # Identify the most frequent port of embarkation\n",
    "        self.most_freq_embarked = ADD CODE HERE\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Replace missing values of Age with the median Age for each class and sex\n",
    "        X.Age = X.groupby(['Sex', 'Pclass'])['Age'].apply(lambda z: z.fillna(z.median()))\n",
    "        \n",
    "        # Fill the single missing value for Fare with the pre-calculated median\n",
    "        X.Fare = X.Fare.fillna(self.med_fare_)\n",
    "        \n",
    "        # Fill missing Embarked values with the most frequent port\n",
    "        X.Embarked = X.Embarked.fillna(self.most_freq_embarked)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-sugar",
   "metadata": {
    "papermill": {
     "duration": 0.047898,
     "end_time": "2021-04-17T23:19:04.204802",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.156904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.2 Feature Engineering:\n",
    "#### 2.2.1 Creating New Features\n",
    "\n",
    "This section focuses on transforming existing attributes and introducing new ones to enhance the dataset:\n",
    "\n",
    "* **Relative On Board Feature:**\n",
    "  - Combine 'Parch' and 'SibSp' to create a new attribute, 'Relative On Board.'\n",
    "\n",
    "* **Family Attribute:**\n",
    "  - Utilize the 'Relative On Board' feature to categorize passengers into:\n",
    "    - 'Alone' if the passenger has no relatives on board.\n",
    "    - 'Small' for passengers with 1 or 2 family members.\n",
    "    - 'Medium' for passengers with 3, 4, or 5 family members.\n",
    "    - 'Large' for passengers with more than 6 family members.\n",
    "\n",
    "* **Deck Attribute:**\n",
    "  - Extract the first letter of the cabin name for each passenger to create the 'Deck' attribute using the 'Cabin' feature.\n",
    "\n",
    "* **Age Transformation:**\n",
    "  - Convert the 'Age' attribute from continuous data into a categorical attribute with 8 distinct categories.\n",
    "\n",
    "* **Fare Transformation:**\n",
    "  - Apply a logarithmic transformation to the 'Fare' attribute to reduce skewness in the distribution.\n",
    "\n",
    "* **Ticket Frequency:**\n",
    "  - Replace the ticket ID with the frequency of each ticket.\n",
    "\n",
    "* **Title Extraction and IsMarried Attribute:**\n",
    "  - Extract the 'Title' attribute from the 'Name' attribute and create an 'IsMarried' attribute based on marital status.\n",
    "\n",
    "These feature engineering steps aim to derive meaningful insights from existing attributes and facilitate the development of robust machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accompanied-developer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:04.304867Z",
     "iopub.status.busy": "2021-04-17T23:19:04.304148Z",
     "iopub.status.idle": "2021-04-17T23:19:04.318458Z",
     "shell.execute_reply": "2021-04-17T23:19:04.319041Z"
    },
    "papermill": {
     "duration": 0.065672,
     "end_time": "2021-04-17T23:19:04.319226",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.253554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom Transformer class for performing feature engineering on a DataFrame.\n",
    "    \n",
    "    This class implements the fit and transform methods, allowing it to be seamlessly integrated\n",
    "    into a sklearn pipeline for preprocessing data.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Combining 'Sibsp' and 'Parch' to create 'RelativesOnboard' and then creating the 'Family' attribute\n",
    "        X[\"RelativesOnboard\"] = ADD CODE HERE\n",
    "        X['Family'] = ADD CODE HERE\n",
    "        \n",
    "        # Extracting the first letter of each cabin to create the 'Deck' attribute\n",
    "        X[\"Deck\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in X['Cabin'] ])  \n",
    "        \n",
    "        # Regrouping 'Deck' categories\n",
    "        X['Deck'] = X['Deck'].replace(['T', 'A', 'B', 'C'], ADD CODE HERE)\n",
    "        X['Deck'] = X['Deck'].replace(['D', 'E'], ADD CODE HERE)\n",
    "        X['Deck'] = X['Deck'].replace(['F', 'G'], ADD CODE HERE)\n",
    "        \n",
    "        # Transforming 'Age' from continuous data into an attribute with 8 categories\n",
    "        X[\"Age\"] = pd.cut(X[\"Age\"], bins=[0., 5.0, 15.0, 25.0, 30.0, 40.0, 50.0, 60.0, np.inf], labels=[1, 2, 3, 4, 5, 6, 7, 8])\n",
    "        \n",
    "        # For 'Fare', applying log transformation to reduce skewness in distribution\n",
    "        X[\"Fare\"] = X[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "        \n",
    "        # Replace ticket ID by ticket frequency\n",
    "        X['Ticket_Frequency'] = X.groupby('Ticket')['Ticket'].transform('count')\n",
    "        \n",
    "        # Extract 'Title' attribute from 'Name' and create 'Is_Married' attribute\n",
    "        X['Title'] = X['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "        X['Is_Married'] = 0\n",
    "        X.loc[X['Title'] == 'Mrs', 'Is_Married'] = 1\n",
    "        \n",
    "        # Grouping 'Title' categories\n",
    "        X['Title'] = X['Title'].replace(['Miss', 'Mrs', 'Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "        X['Title'] = X['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-discrimination",
   "metadata": {
    "papermill": {
     "duration": 0.047919,
     "end_time": "2021-04-17T23:19:04.415593",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.367674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.2 Encoding\n",
    "\n",
    "In this section, we will apply label encoding to the following features:\n",
    "\n",
    "**Label Encoding:**\n",
    "- Age\n",
    "- Fare\n",
    "- Embarked\n",
    "- Sex\n",
    "- Title\n",
    "- Family\n",
    "- RelativesOnboard\n",
    "- Deck\n",
    "\n",
    "Additionally, we will use OneHotEncoding for the following features:\n",
    "\n",
    "**OneHotEncoding:**\n",
    "- Pclass\n",
    "- Sex\n",
    "- Deck\n",
    "- Family\n",
    "- Title\n",
    "- Embarked\n",
    "\n",
    "**Label Encoding:**\n",
    "Label Encoding is a technique used to convert categorical data into numerical format. In this process, each unique category or label is assigned a unique integer. The assigned integers are often in ascending order based on the alphabetical order of the categories. Label Encoding is suitable for ordinal data where the order among categories matters, as it introduces a numerical representation while preserving the ordinal relationships. However, it's important to note that this encoding might inadvertently imply ordinal relationships in non-ordinal categorical variables.\n",
    "\n",
    "For example, in the context of the Titanic dataset:\n",
    "- 'Embarked': {'C', 'Q', 'S'} could be encoded as {'C': 0, 'Q': 1, 'S': 2}.\n",
    "\n",
    "**One-Hot Encoding:**\n",
    "One-Hot Encoding is a technique used to represent categorical data in a binary matrix format. Each category is transformed into a binary column, and the presence or absence of the category is indicated by a 1 or 0, respectively. This method is particularly useful for nominal data where there is no inherent order among categories. One-Hot Encoding avoids introducing unintended ordinal relationships and is compatible with machine learning algorithms that require numerical input.\n",
    "\n",
    "For example, in the context of the Titanic dataset:\n",
    "- 'Embarked': {'C', 'Q', 'S'} could be one-hot encoded as three separate binary columns: 'Embarked_C', 'Embarked_Q', 'Embarked_S', with values {1, 0, 0}, {0, 1, 0}, {0, 0, 1} indicating the presence of each category.\n",
    "\n",
    "In summary, Label Encoding assigns a unique integer to each category, while One-Hot Encoding creates binary columns for each category, representing their presence or absence. The choice between these encoding techniques depends on the nature of the categorical data and the requirements of the machine learning algorithm being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-collins",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:04.521385Z",
     "iopub.status.busy": "2021-04-17T23:19:04.519472Z",
     "iopub.status.idle": "2021-04-17T23:19:04.524554Z",
     "shell.execute_reply": "2021-04-17T23:19:04.523929Z"
    },
    "papermill": {
     "duration": 0.06187,
     "end_time": "2021-04-17T23:19:04.524701",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.462831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoding(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom Transformer class for performing encoding on selected features in a DataFrame.\n",
    "    \n",
    "    This class implements the fit and transform methods, allowing it to be seamlessly integrated\n",
    "    into a sklearn pipeline for preprocessing data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize OneHotEncoder and LabelEncoder\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.le = LabelEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Label encoding\n",
    "        for i in ['Age', 'Fare', 'Embarked', 'Sex', 'Title', 'Family', 'RelativesOnboard', 'Deck']:\n",
    "            X[i] = self.le.fit_transform(X[i])\n",
    "        \n",
    "        # OneHotEncoding\n",
    "        encoded_features = []\n",
    "        for cat in ['Deck', 'Age', 'Pclass', 'Sex', 'Title', 'Embarked', 'Family', 'RelativesOnboard']:\n",
    "            encoded_feat = self.ohe.fit_transform(X[cat].values.reshape(-1, 1)).toarray()\n",
    "            n = X[cat].nunique()\n",
    "            cols = ['{}_{}'.format(cat, n) for n in range(1, n + 1)]\n",
    "            encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "            encoded_df.index = X.index\n",
    "            encoded_features.append(encoded_df)\n",
    "        \n",
    "        # Concatenate encoded features with the original DataFrame\n",
    "        X = pd.concat([X, *encoded_features[:8]], axis=1)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-report",
   "metadata": {
    "papermill": {
     "duration": 0.047701,
     "end_time": "2021-04-17T23:19:04.620833",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.573132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.3 Data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "varied-jason",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:04.723928Z",
     "iopub.status.busy": "2021-04-17T23:19:04.723227Z",
     "iopub.status.idle": "2021-04-17T23:19:04.730881Z",
     "shell.execute_reply": "2021-04-17T23:19:04.729954Z"
    },
    "papermill": {
     "duration": 0.062104,
     "end_time": "2021-04-17T23:19:04.731039",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.668935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnsDrop(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom Transformer class for dropping specified columns from a DataFrame.\n",
    "    \n",
    "    This class implements the fit and transform methods, allowing it to be seamlessly integrated\n",
    "    into a sklearn pipeline for preprocessing data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attribute_names):\n",
    "        # Initialize with a list of attribute names to be dropped\n",
    "        self.attribute_names = attribute_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Drop specified columns from the DataFrame\n",
    "        return X.drop(self.attribute_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nonprofit-investing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:04.839836Z",
     "iopub.status.busy": "2021-04-17T23:19:04.838644Z",
     "iopub.status.idle": "2021-04-17T23:19:04.841999Z",
     "shell.execute_reply": "2021-04-17T23:19:04.841213Z"
    },
    "papermill": {
     "duration": 0.061222,
     "end_time": "2021-04-17T23:19:04.842228",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.781006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropped_columns = [ 'RelativesOnboard','Age', 'Sex','Deck', 'Family', 'Embarked', 'PassengerId', 'Pclass', 'Name', 'Ticket','Cabin','Embarked']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737a8db",
   "metadata": {},
   "source": [
    "Let's create a processing pipeline using scikit-learn's \"Pipeline\" class. A pipeline is a way to streamline a lot of the routine processes by putting together a sequence of data processing steps. In our case, the pipeline consists of four different custom transformers/steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sufficient-background",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:04.947155Z",
     "iopub.status.busy": "2021-04-17T23:19:04.946481Z",
     "iopub.status.idle": "2021-04-17T23:19:04.949931Z",
     "shell.execute_reply": "2021-04-17T23:19:04.949384Z"
    },
    "papermill": {
     "duration": 0.057459,
     "end_time": "2021-04-17T23:19:04.950091",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.892632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_pipeline = ADD CODE HERE([\n",
    "    ('Filling missing values', Imputer()),\n",
    "    ('Feature Engineering', FeatureEngineering()),\n",
    "    ('Encoding', Encoding()),\n",
    "    ('dropping useless columns', ColumnsDrop(dropped_columns) ),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-executive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:05.066586Z",
     "iopub.status.busy": "2021-04-17T23:19:05.065721Z",
     "iopub.status.idle": "2021-04-17T23:19:05.184597Z",
     "shell.execute_reply": "2021-04-17T23:19:05.185350Z"
    },
    "papermill": {
     "duration": 0.186224,
     "end_time": "2021-04-17T23:19:05.185588",
     "exception": false,
     "start_time": "2021-04-17T23:19:04.999364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a copy of train and test\n",
    "X_train= ADD CODE HERE\n",
    "X_test = ADD CODE HERE\n",
    "# Use the pipeline to transform the data using fit_transform\n",
    "X_train = ADD CODE HERE\n",
    "plot_correlations(X_train)\n",
    "# Assign the target variable to y_train\n",
    "y_train = ADD CODE HERE\n",
    "# DROP THE SURVIVED COLUMN FROM X_train\n",
    "X_train = X_train.drop('Survived',axis=1 )\n",
    "# Use the pipeline to transform the test data using transform\n",
    "X_test = ADD CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40442d7d",
   "metadata": {},
   "source": [
    "In machine learning, the `fit_transform` method is used during the training phase to both fit the transformation parameters and apply the transformation to the training dataset, while the `transform` method is used during the testing phase to apply the previously learned transformation to the new, unseen data.\n",
    "\n",
    "Here's why we use `fit_transform` for training and only `transform` for testing:\n",
    "\n",
    "1. **Training Phase (`fit_transform`):**\n",
    "   - During the training phase, the pipeline needs to learn and adapt to the characteristics of the training data. The `fit_transform` method is used to fit the transformers (such as imputers, encoders, etc.) to the training data and simultaneously apply the transformations. This ensures that the statistical properties and mappings learned from the training data are correctly applied to prepare the features for the machine learning model.\n",
    "\n",
    "   ```python\n",
    "   # Fitting and transforming the training data\n",
    "   X_train = processing_pipeline.fit_transform(X_train)\n",
    "   ```\n",
    "\n",
    "2. **Testing Phase (`transform`):**\n",
    "   - In the testing phase, the pipeline has already been fitted and learned from the training data. We want to apply the same transformations to the test data that were learned from the training data. However, we don't want to re-fit the transformers based on the test data, as this would introduce data leakage and compromise the integrity of the evaluation. Instead, we only use the `transform` method, which applies the previously learned transformations without modifying the parameters.\n",
    "\n",
    "   ```python\n",
    "   # Transforming the test data using the learned transformations\n",
    "   X_test = processing_pipeline.transform(X_test)\n",
    "   ```\n",
    "\n",
    "This separation between fitting and transforming ensures that the pipeline generalizes well to unseen data and maintains the consistency of the preprocessing steps between the training and testing datasets. It aligns with the principle of keeping the testing phase isolated from the training phase to obtain reliable performance metrics for the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-killing",
   "metadata": {
    "papermill": {
     "duration": 0.048573,
     "end_time": "2021-04-17T23:19:05.284058",
     "exception": false,
     "start_time": "2021-04-17T23:19:05.235485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **3. Modeling**\n",
    "#### 3.1 Evaluating Models and Making a Choice\n",
    "\n",
    "In this section, we assess the performance of several well-known models on the dataset and select those that demonstrate high accuracy. To ensure robust evaluation, we employ 10-fold cross-validation to measure performance on the training data. This allows us to make an informed decision based on the models' effectiveness in handling the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "noticed-hobby",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:05.389253Z",
     "iopub.status.busy": "2021-04-17T23:19:05.388218Z",
     "iopub.status.idle": "2021-04-17T23:19:05.391508Z",
     "shell.execute_reply": "2021-04-17T23:19:05.390848Z"
    },
    "papermill": {
     "duration": 0.058773,
     "end_time": "2021-04-17T23:19:05.391660",
     "exception": false,
     "start_time": "2021-04-17T23:19:05.332887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8da12",
   "metadata": {},
   "source": [
    "#### Performance Metric: Accuracy\n",
    "\n",
    "Accuracy is performance metric usedin machine learning to evaluate the effectiveness of a model or a classifier. It represents the proportion of correctly classified instances among the total instances evaluated. In simple terms, accuracy measures how often a model makes correct predictions. It is calculated by dividing the number of correct predictions by the total number of predictions made. Mathematically, accuracy can be expressed as:\n",
    "\n",
    "Accuracy = (Number of Correct Predictions / Total Number of Predictions) * 100%\n",
    "\n",
    "**Interpreting Accuracy:**\n",
    "\n",
    "- A high accuracy score indicates that the model is making correct predictions most of the time.\n",
    "- Conversely, a low accuracy score suggests that the model's predictions are often incorrect.\n",
    "- It is important to note that accuracy alone may not provide a comprehensive understanding of a model's performance, especially in scenarios where the dataset is imbalanced or when different types of errors have varying consequences.\n",
    "\n",
    "**Considerations and Limitations:**\n",
    "\n",
    "- Accuracy is a valuable metric but may not always be sufficient for evaluating the performance of a model, particularly in scenarios where class distribution is uneven.\n",
    "- In cases of imbalanced datasets, where one class dominates the others, a model may achieve high accuracy by simply predicting the majority class most of the time. In such cases, other performance metrics like precision, recall, or F1-score provide a more nuanced evaluation. These metrics provide insights into different aspects of a model's performance, such as its ability to correctly identify positive instances (precision), its ability to capture all positive instances (recall), and the balance between precision and recall (F1-score).\n",
    "- Moreover, accuracy does not consider the types of errors made by the model. It treats all misclassifications equally, which may not be suitable for applications where certain types of errors are more critical than others.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "The confusion matrix is another valuable tool for understanding the performance of a classifier. It provides a tabular summary of the model's predictions compared to the actual class labels, allowing analysts to identify patterns of correct and incorrect classifications across different classes. This information can be used to diagnose specific types of errors made by the model and to fine-tune its performance.\n",
    "\n",
    "For more details on Confusion matrix and other measures for classification you can check this [blog](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-litigation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:05.500700Z",
     "iopub.status.busy": "2021-04-17T23:19:05.499975Z",
     "iopub.status.idle": "2021-04-17T23:19:11.210173Z",
     "shell.execute_reply": "2021-04-17T23:19:11.209523Z"
    },
    "papermill": {
     "duration": 5.769079,
     "end_time": "2021-04-17T23:19:11.210328",
     "exception": false,
     "start_time": "2021-04-17T23:19:05.441249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define number of splits for StratifiedKFold and random state\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "# Initialize a list to store classifiers\n",
    "classifiers = [\n",
    "    SVC(random_state=42),\n",
    "    ADD CODE HERE,\n",
    "    ADD CODE HERE,\n",
    "    ADD CODE HERE,\n",
    "    ADD CODE HERE\n",
    "]\n",
    "\n",
    "# Initialize lists to store cross-validation results\n",
    "cv_results = []\n",
    "\n",
    "# Perform cross-validation for each classifier\n",
    "for classifier in classifiers:\n",
    "    cv_results.append(cross_val_score(ADD CODE HERE, ADD CODE HERE, y=ADD CODE HERE, scoring=ADD CODE HERE, cv=kfold, n_jobs=4))\n",
    "\n",
    "# Calculate mean and standard deviation of cross-validation results\n",
    "cv_means = [cv_result.mean() for cv_result in cv_results]\n",
    "cv_std = [cv_result.std() for cv_result in cv_results]\n",
    "\n",
    "# Create a DataFrame to display cross-validation results\n",
    "cv_res = pd.DataFrame({\n",
    "    \"Algorithm\": [\"SVC\", \"DecisionTree\", \"RandomForest\", \"GradientBoosting\", \"ExtraTrees\"],\n",
    "    \"CrossValMeans\": cv_means,\n",
    "    \"CrossValErrors\": cv_std\n",
    "})\n",
    "\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-sister",
   "metadata": {
    "papermill": {
     "duration": 0.048777,
     "end_time": "2021-04-17T23:19:11.308384",
     "exception": false,
     "start_time": "2021-04-17T23:19:11.259607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What are the most two promosing models?\n",
    "Continue your code using them. For us we will be using Random Forest and GB. Feel free to look up sklean website and test other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-violence",
   "metadata": {
    "papermill": {
     "duration": 0.049015,
     "end_time": "2021-04-17T23:19:11.406755",
     "exception": false,
     "start_time": "2021-04-17T23:19:11.357740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2 Hypter parameter tunning and combining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-transportation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:11.514244Z",
     "iopub.status.busy": "2021-04-17T23:19:11.513483Z",
     "iopub.status.idle": "2021-04-17T23:19:11.515680Z",
     "shell.execute_reply": "2021-04-17T23:19:11.516177Z"
    },
    "papermill": {
     "duration": 0.060748,
     "end_time": "2021-04-17T23:19:11.516358",
     "exception": false,
     "start_time": "2021-04-17T23:19:11.455610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [ 20 ,'auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "rf_param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "circular-dominant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:11.619308Z",
     "iopub.status.busy": "2021-04-17T23:19:11.618522Z",
     "iopub.status.idle": "2021-04-17T23:19:11.625081Z",
     "shell.execute_reply": "2021-04-17T23:19:11.625570Z"
    },
    "papermill": {
     "duration": 0.059984,
     "end_time": "2021-04-17T23:19:11.625764",
     "exception": false,
     "start_time": "2021-04-17T23:19:11.565780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for details on these HP visit sklearn website\n",
    "# The number of boosting stages to perform\n",
    "n_estimators = ADD CODE HERE\n",
    "# Number of features to consider at every split\n",
    "max_features = ADD CODE HERE\n",
    "# Maximum number of levels in tree\n",
    "max_depth = ADD CODE HERE\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = ADD CODE HERE\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = ADD CODE HERE\n",
    "# The function to measure the quality of a split\n",
    "# Create the random grid\n",
    "gb_param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628b746",
   "metadata": {},
   "source": [
    "In the process of hyperparameter tuning, we use GridSearchCV to systematically search through a specified grid of hyperparameter values for a Random Forest Classifier. Hyperparameters are external configuration settings that are not learned from the data but significantly impact the model's performance. The grid (`rf_param_grid`) contains various combinations of hyperparameters such as the number of estimators, maximum features, maximum depth, minimum samples split, and minimum samples leaf.\n",
    "\n",
    "The `GridSearchCV` class performs an exhaustive search over the specified hyperparameter values, evaluating each combination using cross-validation. The best-performing model, based on the specified scoring metric (accuracy in this case), is then identified. After fitting the grid search to the training data, the best Random Forest Classifier (`RFC_best`) is obtained with the optimal hyperparameters. The best cross-validated score is displayed to provide insight into the performance improvement achieved through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-values",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:19:11.730631Z",
     "iopub.status.busy": "2021-04-17T23:19:11.729631Z",
     "iopub.status.idle": "2021-04-17T23:26:08.942504Z",
     "shell.execute_reply": "2021-04-17T23:26:08.943049Z"
    },
    "papermill": {
     "duration": 417.267361,
     "end_time": "2021-04-17T23:26:08.943237",
     "exception": false,
     "start_time": "2021-04-17T23:19:11.675876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV for Random Forest\n",
    "Grid_s_rf = GridSearchCV(rf, param_grid=rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs=-1, verbose=True)\n",
    "\n",
    "# Fit the model to find the best hyperparameters\n",
    "Grid_s_rf.ADD CODE HERE\n",
    "\n",
    "# Obtain the best estimator with optimal hyperparameters\n",
    "RFC_best = Grid_s_rf.best_estimator_\n",
    "\n",
    "# Display the best cross-validated score\n",
    "Grid_s_rf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-inspection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:26:09.065847Z",
     "iopub.status.busy": "2021-04-17T23:26:09.064864Z",
     "iopub.status.idle": "2021-04-17T23:43:15.549168Z",
     "shell.execute_reply": "2021-04-17T23:43:15.549723Z"
    },
    "papermill": {
     "duration": 1026.546477,
     "end_time": "2021-04-17T23:43:15.549907",
     "exception": false,
     "start_time": "2021-04-17T23:26:09.003430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Hyperparameter Tuning\n",
    "gbc = ADD CODE HERE \n",
    "\n",
    "# Initialize GridSearchCV for Gradient Boosting\n",
    "Grid_s_gb = ADD CODE HERE\n",
    "\n",
    "# Fit the model to find the best hyperparameters\n",
    "ADD CODE HERE \n",
    "\n",
    "# Obtain the best estimator with optimal hyperparameters\n",
    "GBC_best = ADD CODE HERE\n",
    "\n",
    "# Display the best cross-validated score\n",
    "Grid_s_gb.ADD CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-hawaii",
   "metadata": {
    "papermill": {
     "duration": 0.121633,
     "end_time": "2021-04-17T23:43:15.723438",
     "exception": false,
     "start_time": "2021-04-17T23:43:15.601805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For each model, we have explored 216 candidate hyperparameter combinations, fitting each configuration over 10 folds, resulting in a total of 2160 fits. From this extensive search, we will identify the top two performing models and then combine their predictions using the ensemble method known as VotingClassifier. This ensemble approach aims to harness the strengths of multiple models, leading to a more robust and potentially higher-performing predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "moral-express",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:43:15.830330Z",
     "iopub.status.busy": "2021-04-17T23:43:15.829560Z",
     "iopub.status.idle": "2021-04-17T23:43:16.164346Z",
     "shell.execute_reply": "2021-04-17T23:43:16.163693Z"
    },
    "papermill": {
     "duration": 0.389365,
     "end_time": "2021-04-17T23:43:16.164495",
     "exception": false,
     "start_time": "2021-04-17T23:43:15.775130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Combining 2 models\n",
    "votingC = VotingClassifier(estimators=[('rfc', RFC_best),('gbc',GBC_best)], voting='soft', n_jobs=-1)\n",
    "votingC = votingC.ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-malta",
   "metadata": {
    "papermill": {
     "duration": 0.051281,
     "end_time": "2021-04-17T23:43:16.267438",
     "exception": false,
     "start_time": "2021-04-17T23:43:16.216157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **4. Submitting results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faced-enhancement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-17T23:43:16.378642Z",
     "iopub.status.busy": "2021-04-17T23:43:16.377993Z",
     "iopub.status.idle": "2021-04-17T23:43:16.410769Z",
     "shell.execute_reply": "2021-04-17T23:43:16.410120Z"
    },
    "papermill": {
     "duration": 0.092055,
     "end_time": "2021-04-17T23:43:16.410920",
     "exception": false,
     "start_time": "2021-04-17T23:43:16.318865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = votingC.predict(X_test)\n",
    "submission = pd.DataFrame({'PassengerId': test.PassengerId,\n",
    "                           'Survived': predictions})\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "# Now you can submit the file to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-extension",
   "metadata": {
    "papermill": {
     "duration": 0.051398,
     "end_time": "2021-04-17T23:43:16.514109",
     "exception": false,
     "start_time": "2021-04-17T23:43:16.462711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exercise:\n",
    "1. Test more models and more Hyper paramaters.\n",
    "2. Apply more data visualizations techniques.\n",
    "3. Test different features. Hint: add or drop.\n",
    "4. Look at feature importance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1466.972259,
   "end_time": "2021-04-17T23:43:17.677769",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-17T23:18:50.705510",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
